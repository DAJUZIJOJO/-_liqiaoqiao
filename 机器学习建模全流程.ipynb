{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888c6a95",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'thrift'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30396/3741808964.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyhive\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\shazi\\lib\\site-packages\\pyhive\\hive.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mTCLIService\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTCLIService\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTCLIService\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTCLIService\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mttypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\shazi\\lib\\site-packages\\TCLIService\\TCLIService.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mthrift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mThrift\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTMessageType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFrozenDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTApplicationException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthrift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTProtocol\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTProtocolException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'thrift'"
     ]
    }
   ],
   "source": [
    "from pyhive import hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc617049",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'thrift'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30396/1368691711.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyhive\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\shazi\\lib\\site-packages\\pyhive\\hive.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mTCLIService\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTCLIService\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTCLIService\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTCLIService\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mttypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\shazi\\lib\\site-packages\\TCLIService\\TCLIService.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mthrift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mThrift\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTMessageType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFrozenDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTApplicationException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthrift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTProtocol\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTProtocolException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'thrift'"
     ]
    }
   ],
   "source": [
    "from pyhive import hive\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rc('figure', max_open_warning = 0)  # 解决图片输出过多警告\n",
    "import scorecardpy\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit,ShuffleSplit,StratifiedKFold,KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,r2_score,mean_squared_error,accuracy_score,precision_score,log_loss,roc_auc_score,recall_score,f1_score\n",
    "import statsmodels.api as sm \n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import graphviz\n",
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from pygam import LinearGAM,LogisticGAM\n",
    "import itertools\n",
    "from ipykernel import kernelapp as app\n",
    "\n",
    "\n",
    "from pandas import DataFrame,Series\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy.stats import bartlett\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import math as math\n",
    "from numpy import *\n",
    "import numpy.linalg as nlg\n",
    "from factor_analyzer import factor_analyzer,Rotator\n",
    "from factor_analyzer import FactorAnalyzer, calculate_kmo, calculate_bartlett_sphericity  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8dcbfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://didiyum.sys.xiaojukeji.com/didiyum/pip/simple/"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0x0000016B00A18850>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /didiyum/pip/simple/graphviz/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0x0000016B00A18BB0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /didiyum/pip/simple/graphviz/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0x0000016B00A18DC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /didiyum/pip/simple/graphviz/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0x0000016B00A18FA0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /didiyum/pip/simple/graphviz/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0x0000016B00A3E220>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /didiyum/pip/simple/graphviz/\n",
      "ERROR: Could not find a version that satisfies the requirement graphviz (from versions: none)\n",
      "ERROR: No matching distribution found for graphviz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#安装包\n",
    "!pip install --trusted-host didiyum.sys.xiaojukeji.com -i http://didiyum.sys.xiaojukeji.com/didiyum/pip/simple/  graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5566563",
   "metadata": {},
   "source": [
    "# 1.函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07caa1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## 1.1 drop_duplicates() \n",
    "去掉重复值\n",
    "\n",
    "df = pd.DataFrame(data={'height':[178,178,185,196],'weight':[156,90,140,142],'name':['小狗','小狗','小狗','小猪']})\n",
    "df1=df.drop_duplicates().loc[0]['name']\n",
    "df2=df.drop_duplicates(subset='name')# 删除name列中的重复值\n",
    "df3=df.drop_duplicates(subset=['name','height'])# 当height和name列的值都重复时，删掉重复值\n",
    "df4=df.drop_duplicates(subset=['name','height'],keep = 'last')#保留最后一次出现的重复值\n",
    "#ignore_index: bool,default False布尔值，默认为False;如果为True，会对结果重新排序\n",
    "df7=df.drop_duplicates(subset=['name','height'],keep = 'last',ignore_index=True)\n",
    "df7\n",
    "\n",
    "## 1.2 sort_values()\n",
    "DataFrame.sort_values(by, ascending=True, inplace=False)\n",
    "\n",
    "ivs=iv.sort_values(['iv'],ascending=False)#排序\n",
    "#by：字符串或者List<字符串>，单列排序或者多列排序\n",
    "#ascending：bool或者List，升序还是降序，如果是list对应by的多列\n",
    "#inplace：是否修改原始DataFrame\n",
    "df21=df.sort_values(['weight'],ascending=False)#由高到低\n",
    "df22=df.sort_values(['height'],inplace=False)#不改变原数据\n",
    "\n",
    "## 其他\n",
    "\n",
    "vif = pd.merge(vif,iv,how='left',on='features')#左连接\n",
    "df=pd.concat([y,df[p0],df[p1]],axis=1)#合并\n",
    "itertools.product(col,col)#product(A, B)函数，返回A、B中的元素的笛卡尔积的元组\n",
    "df=df.drop(['msg_gap'],axis=1)#删除\n",
    "\n",
    "# 添加交叉项   \n",
    "col=list(dff.columns[1:])\n",
    "for i,j in itertools.product(col,col):\n",
    "#    if j==i:   # 取全部的交叉项➡️j>=i，取平方项j==i\n",
    "        dff[i+j]=dff[i]*dff[j]\n",
    "#    else:\n",
    "#        continue\n",
    "dff.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a8512",
   "metadata": {},
   "source": [
    "# 2.数据清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21635676",
   "metadata": {},
   "source": [
    "## 2.1插补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a0f7129",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#常数插补0\n",
    "df['days_since_first_visit'] =  df['days_since_first_visit'].fillna(0)\n",
    "df=df.fillna(0)#全列插补\n",
    "\n",
    "#循环插补\n",
    "df1=df.iloc[:,8:]\n",
    "for i in df1.columns.values.tolist():\n",
    "    df1[i] =  df1[i].fillna(0)\n",
    "df1.isnull().sum()\n",
    "df1.isna().mean()\n",
    "df1.to_csv('41_1221.csv')\n",
    "df1.head()\n",
    "\n",
    "#众数插补\n",
    "for i in df1.columns.values.tolist():\n",
    "    df1[i] =  df1[i].fillna(df1[i].mode()[0])\n",
    "df1.isnull().sum()\n",
    "\n",
    "df1.to_csv('78visit0.csv',index=0,header=1)\n",
    "\n",
    "#空值填充\n",
    "df['msg_gap'] =  df['msg_gap'].fillna('a')\n",
    "#插入\n",
    "df.insert(2,'missing_gap',0)#不要也可\n",
    "#条件/增加一列\n",
    "df['missing_gap']=np.where(df['msg_gap']=='a',1,0)\n",
    "#替换\n",
    "df.loc[df[\"msg_gap\"] == 'a',\"msg_gap\"] = 0\n",
    "df = df.fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4f3da",
   "metadata": {},
   "source": [
    "## 2.2数据增加和删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b1e0e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#增加一列\n",
    "#增加一列,购买量,购买量超过3的为高，低于3的为底\n",
    "df['购买量'] = np.where(df['buy_mount'] >3,'高','低')\n",
    "df.head(3)\n",
    "\n",
    "#删除列\n",
    "del df['auction_id']\n",
    "df.head(3)\n",
    "\n",
    "df.insert(0, 'auction_id', auction_id)\n",
    "df.head(5)\n",
    "\n",
    "# axis=0按行操作, axis=1按列操作\n",
    "df.drop(labels = ['property', '购买量'],axis = 1,inplace=True) #删除这两列,加inplace代表是否在原数据上操作, 1代表沿着列的方向\n",
    "df.drop(labels = [3,4],inplace = True,axis= 0) # 删除索引标签3和4对应的行\n",
    "df.drop(labels= range(1,10),axis=0,inplace=True)  #删除索引名称1到10,注意range迭代器产生的是1到10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d7426b",
   "metadata": {},
   "source": [
    "## 2.3数据修改和查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "417ce9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将gender为0的改为女性，1改为男性，2改为未知\n",
    "df1.loc[df['gender'] =='0','gender'] ='女性'\n",
    "df1.loc[df['gender'] =='1','gender'] ='男性'\n",
    "df1.loc[df['gender'] =='2','gender'] ='未知'\n",
    "df1.head(3)\n",
    "\n",
    "#修改列名称\n",
    "#basic.rename(columns={},index={})\n",
    "\n",
    "# 修改列标签和行索引名称\n",
    "df1.rename(columns = {'user_id':'用户ID','birthday':'出生日期','gender':'性别'},inplace = True)\n",
    "df1.rename(index = {1:'one',10:'ten' },inplace = True) #修改行索引名称\n",
    "df1.reset_index(drop=True,inplace=True)# 重置索引\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76826b5e",
   "metadata": {},
   "source": [
    "## 2.4条件筛选"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c595b6",
   "metadata": {},
   "source": [
    "### 查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853ed786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 条件查询\n",
    "df[(df.buy_mount > 3)]#性别等于未知\n",
    "df[~(df.buy_mount > 3)] # ~代表非\n",
    "df[ (df.buy_mount > 3) &  (df.day > 20140101)] # 多条件查询\n",
    "#使用between,inclusive=True代表包含\n",
    "df[ df['buy_mount'].between(4,10,inclusive=True)]\n",
    "\n",
    "df.loc[df.user_id =='786295544',['user_id','buy_mount','day']]\n",
    "df.loc[(df.user_id =='786295544') | (df.user_id =='444069173'),['user_id','buy_mount','day']]# 多个条件选择\n",
    "\n",
    "test_df12610=pd.read_csv('test_df126.csv')\n",
    "df4 = test_df12610.loc[(test_df12610.y_prob >=0.04)|(test_df12610.y_prob <=0.1),['credit_apply_flag']]#[['credit_apply_flag','y_prob']]\n",
    "a1=df4[df4['credit_apply_flag'] ==1].count()\n",
    "a2=df4[df4['credit_apply_flag'] ==0].count()\n",
    "a3=df4.count()\n",
    "print(a1/a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4d5030e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>cat_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat1</th>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">28</th>\n",
       "      <th>532110457</th>\n",
       "      <td>17916191097</td>\n",
       "      <td>50011993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82830661</th>\n",
       "      <td>19948600790</td>\n",
       "      <td>50013874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 auction_id    cat_id\n",
       "cat1 user_id                         \n",
       "28   532110457  17916191097  50011993\n",
       "     82830661   19948600790  50013874"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(28,[82830661,532110457]),['auction_id','cat_id']]# 第二层索引选择，选择2个变量\n",
    "df.loc[([28,50014815])] #第一层索引为28和50014815"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f7ad3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### 关联"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "806c498c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>auction_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>property</th>\n",
       "      <th>buy_mount</th>\n",
       "      <th>day</th>\n",
       "      <th>birthday</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>513441334</td>\n",
       "      <td>19909384116</td>\n",
       "      <td>50010557</td>\n",
       "      <td>50008168</td>\n",
       "      <td>25935:21991;1628665:29784;22019:34731;22019:20...</td>\n",
       "      <td>1</td>\n",
       "      <td>20121212</td>\n",
       "      <td>20110105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>377550424</td>\n",
       "      <td>15771663914</td>\n",
       "      <td>50015841</td>\n",
       "      <td>28</td>\n",
       "      <td>1628665:3233941;1628665:3233942;3914866:11580;...</td>\n",
       "      <td>1</td>\n",
       "      <td>20121123</td>\n",
       "      <td>20110620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47342027</td>\n",
       "      <td>14066344263</td>\n",
       "      <td>50013636</td>\n",
       "      <td>50008168</td>\n",
       "      <td>21458:21599;13585028:3416646;1628665:3233942;1...</td>\n",
       "      <td>1</td>\n",
       "      <td>20120911</td>\n",
       "      <td>20101008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119784861</td>\n",
       "      <td>20796936076</td>\n",
       "      <td>50140021</td>\n",
       "      <td>50008168</td>\n",
       "      <td>21458:120325094;22019:2026;22019:34731;22019:3...</td>\n",
       "      <td>1</td>\n",
       "      <td>20121129</td>\n",
       "      <td>20120327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159129426</td>\n",
       "      <td>15198386301</td>\n",
       "      <td>50013711</td>\n",
       "      <td>50008168</td>\n",
       "      <td>21458:11580;1628665:29778;22019:3340598;22019:...</td>\n",
       "      <td>2</td>\n",
       "      <td>20120808</td>\n",
       "      <td>20100825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645596397</td>\n",
       "      <td>20115324762</td>\n",
       "      <td>50010549</td>\n",
       "      <td>50008168</td>\n",
       "      <td>21458:11580;25935:31381;1628665:3233942;162866...</td>\n",
       "      <td>1</td>\n",
       "      <td>20121130</td>\n",
       "      <td>20130220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>757254614</td>\n",
       "      <td>35900705534</td>\n",
       "      <td>50013711</td>\n",
       "      <td>50008168</td>\n",
       "      <td>1628665:29798;1628665:29785;22019:3284610;2201...</td>\n",
       "      <td>1</td>\n",
       "      <td>20131220</td>\n",
       "      <td>20090528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>275261625</td>\n",
       "      <td>23062392785</td>\n",
       "      <td>50010558</td>\n",
       "      <td>50008168</td>\n",
       "      <td>25935:21991;1628665:3233941;22019:3284610;2201...</td>\n",
       "      <td>1</td>\n",
       "      <td>20130610</td>\n",
       "      <td>20100525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35832151</td>\n",
       "      <td>19178578964</td>\n",
       "      <td>50012451</td>\n",
       "      <td>50008168</td>\n",
       "      <td>1628665:3233942;1628665:3233939;1628665:92012;...</td>\n",
       "      <td>1</td>\n",
       "      <td>20140228</td>\n",
       "      <td>20090401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1834895775</td>\n",
       "      <td>43246645145</td>\n",
       "      <td>50010544</td>\n",
       "      <td>50008168</td>\n",
       "      <td>21458:159383086;13023209:125784;25935:31381;16...</td>\n",
       "      <td>1</td>\n",
       "      <td>20150102</td>\n",
       "      <td>20090515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id   auction_id    cat_id      cat1  \\\n",
       "0   513441334  19909384116  50010557  50008168   \n",
       "1   377550424  15771663914  50015841        28   \n",
       "2    47342027  14066344263  50013636  50008168   \n",
       "3   119784861  20796936076  50140021  50008168   \n",
       "4   159129426  15198386301  50013711  50008168   \n",
       "5   645596397  20115324762  50010549  50008168   \n",
       "6   757254614  35900705534  50013711  50008168   \n",
       "7   275261625  23062392785  50010558  50008168   \n",
       "8    35832151  19178578964  50012451  50008168   \n",
       "9  1834895775  43246645145  50010544  50008168   \n",
       "\n",
       "                                            property  buy_mount       day  \\\n",
       "0  25935:21991;1628665:29784;22019:34731;22019:20...          1  20121212   \n",
       "1  1628665:3233941;1628665:3233942;3914866:11580;...          1  20121123   \n",
       "2  21458:21599;13585028:3416646;1628665:3233942;1...          1  20120911   \n",
       "3  21458:120325094;22019:2026;22019:34731;22019:3...          1  20121129   \n",
       "4  21458:11580;1628665:29778;22019:3340598;22019:...          2  20120808   \n",
       "5  21458:11580;25935:31381;1628665:3233942;162866...          1  20121130   \n",
       "6  1628665:29798;1628665:29785;22019:3284610;2201...          1  20131220   \n",
       "7  25935:21991;1628665:3233941;22019:3284610;2201...          1  20130610   \n",
       "8  1628665:3233942;1628665:3233939;1628665:92012;...          1  20140228   \n",
       "9  21458:159383086;13023209:125784;25935:31381;16...          1  20150102   \n",
       "\n",
       "   birthday gender  \n",
       "0  20110105      1  \n",
       "1  20110620      1  \n",
       "2  20101008      1  \n",
       "3  20120327      0  \n",
       "4  20100825      0  \n",
       "5  20130220      0  \n",
       "6  20090528      0  \n",
       "7  20100525      0  \n",
       "8  20090401      1  \n",
       "9  20090515      0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#关联字段必须类型一致\n",
    "df = pd.read_csv('baby_trade_history.csv', encoding='utf-8',dtype={'user_id':str})# 交易数据\n",
    "df1 = pd.read_csv('sam_tianchi_mum_baby.csv',encoding = 'utf-8',dtype =str)#婴儿信息\n",
    "df2 = pd.merge(left = df, right=df1,  how='inner',  left_on='user_id', right_on = 'user_id')# 内连接\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "106094b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_apply_flag</th>\n",
       "      <th>previous_msg</th>\n",
       "      <th>missing_interval</th>\n",
       "      <th>missing_wl</th>\n",
       "      <th>missing_gap</th>\n",
       "      <th>msg_gap</th>\n",
       "      <th>enter_wl_days</th>\n",
       "      <th>finish_orders</th>\n",
       "      <th>night_finish_orders</th>\n",
       "      <th>week_finish_orders</th>\n",
       "      <th>...</th>\n",
       "      <th>otherpayment_gmv</th>\n",
       "      <th>creditcard_num</th>\n",
       "      <th>otherpayment_num</th>\n",
       "      <th>avg_mile</th>\n",
       "      <th>last_call_interval</th>\n",
       "      <th>last_gmv</th>\n",
       "      <th>other_order_amt</th>\n",
       "      <th>avg_gmv</th>\n",
       "      <th>regist_day</th>\n",
       "      <th>city_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.440000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>263.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>167.380000</td>\n",
       "      <td>616.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1032.79</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6.723846</td>\n",
       "      <td>6.0</td>\n",
       "      <td>124.61</td>\n",
       "      <td>773.92</td>\n",
       "      <td>67.016670</td>\n",
       "      <td>614.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18.375000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>165.80</td>\n",
       "      <td>92.10</td>\n",
       "      <td>128.950000</td>\n",
       "      <td>618.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.35</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>128.81</td>\n",
       "      <td>30.751667</td>\n",
       "      <td>615.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>229.82</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.035000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>94.58</td>\n",
       "      <td>229.82</td>\n",
       "      <td>94.580000</td>\n",
       "      <td>615.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_apply_flag  previous_msg  missing_interval  missing_wl  missing_gap  \\\n",
       "0                  1             0                 0           0            1   \n",
       "1                  1             0                 0           0            1   \n",
       "2                  1             0                 0           0            1   \n",
       "3                  1             0                 0           0            1   \n",
       "4                  1             0                 0           0            1   \n",
       "\n",
       "   msg_gap  enter_wl_days  finish_orders  night_finish_orders  \\\n",
       "0      0.0            0.0            3.0                  0.0   \n",
       "1      0.0            0.0           12.0                  0.0   \n",
       "2      0.0            2.0            2.0                  0.0   \n",
       "3      0.0            2.0            6.0                  0.0   \n",
       "4      0.0            2.0            1.0                  0.0   \n",
       "\n",
       "   week_finish_orders  ...  otherpayment_gmv  creditcard_num  \\\n",
       "0                 1.0  ...            115.24               1   \n",
       "1                 6.0  ...           1032.79               2   \n",
       "2                 1.0  ...              0.00               2   \n",
       "3                 3.0  ...             88.35               3   \n",
       "4                 1.0  ...            229.82               0   \n",
       "\n",
       "   otherpayment_num   avg_mile  last_call_interval  last_gmv  other_order_amt  \\\n",
       "0                 1  20.440000                 3.0    263.80             0.00   \n",
       "1                11   6.723846                 6.0    124.61           773.92   \n",
       "2                 0  18.375000                 4.0    165.80            92.10   \n",
       "3                 3   1.566667                 1.0     24.75           128.81   \n",
       "4                 2  12.035000                27.0     94.58           229.82   \n",
       "\n",
       "      avg_gmv  regist_day  city_type  \n",
       "0  167.380000       616.0          1  \n",
       "1   67.016670       614.0          1  \n",
       "2  128.950000       618.0          1  \n",
       "3   30.751667       615.0          0  \n",
       "4   94.580000       615.0          1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X/Y重组\n",
    "y = df['credit_apply_flag']\n",
    "fea = pd.concat([df['previous_msg'],df.iloc[:,2:]],axis=1)\n",
    "df = pd.concat([y,fea],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d6840",
   "metadata": {},
   "source": [
    "## 2.5异常值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f1b4e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### 删除缺失较多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "020ab60f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 删除所有样本中缺失值超过30%的行\n",
    "def del_rows(data):\n",
    "    t = int(0.7*data.shape[1])\n",
    "    data = data.dropna(thresh=t)#保留至少有 t 个非空的行\n",
    "    #data = data[(data.T != 0).any()]\n",
    "    return data\n",
    "\n",
    "###删除所有行中缺失值超过30%的列\n",
    "def remcolumns(data):\n",
    "    t = int(0.7*data.shape[0])\n",
    "    data = data.dropna(thresh=t,axis=1)#保留至少有 t 个非空的列\n",
    "    #data = data.loc[:, (data != 0).any(axis=0)]\n",
    "    return data\n",
    "\n",
    "# 删缺失列\n",
    "miss = df.isnull().sum()/df.shape[0]\n",
    "droplist = list(miss[miss>=0.9].index)\n",
    "droplist\n",
    "# list(miss[miss==0].index)\n",
    "missco = list(miss[(miss>0)&(miss<0.9)].index)\n",
    "missco\n",
    "\n",
    "# 删除存在空值的变量中全是空值的行\n",
    "df = df.dropna(axis=0,how='all',subset=missco)  # thresh=len(df.columns)\n",
    "df.shape\n",
    "\n",
    "# 删唯一值\n",
    "nui = df.nunique()\n",
    "droplist = list(nui[nui==1].index)\n",
    "droplist\n",
    "# droplist.remove('bind_card')\n",
    "df=df.drop(droplist,axis=1)\n",
    "df.shape\n",
    "\n",
    "# 删同一值占比\n",
    "pct = pd.DataFrame()\n",
    "pct['feature'] = [i for i in list(df.columns[1:])]\n",
    "pct['pct'] = [(df[i].value_counts()/df.shape[0]).values.max() for i in list(df.columns[1:])]\n",
    "pct[pct.pct>=0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db828917",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### 分位数替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "247d6df2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#异常值处理-99分位数替换\n",
    "for i in list(df2.columns[1:]):\n",
    "    df2[i]=np.where(df[i]>=np.percentile(df[i],95),np.percentile(df[i],95),df[i])\n",
    "df2.head()\n",
    "\n",
    "df2.skew(axis=0)\n",
    "\n",
    "# 特征直方图\n",
    "df2.hist(bins=30,figsize=(15,15))\n",
    "plt.figure()\n",
    "\n",
    "# 右偏\n",
    "a=[i for i in list(sk[sk>1].index) if i != 'credit_apply_flag']\n",
    "for i in a:\n",
    "    dff[i]=np.where(dff[i]>=np.percentile(dff[i],97),np.percentile(dff[i],97),dff[i])\n",
    "dff.head()\n",
    "\n",
    "# 左偏\n",
    "b=[i for i in list(sk[sk<-1].index)]\n",
    "for i in b:\n",
    "    dff[i]=np.where(dff[i]<=np.percentile(dff[i],3),np.percentile(dff[i],3),dff[i])\n",
    "dff.head()\n",
    "\n",
    "# 特征直方图\n",
    "dff.hist(bins=30,figsize=(10,10))\n",
    "plt.figure()\n",
    "\n",
    "#偏度\n",
    "dff.skew(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80132b5",
   "metadata": {},
   "source": [
    "## 2.6相关系数热力图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec642894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_corr = df.corr()\n",
    "plt.figure(figsize=(30,5),dpi=60,facecolor='w')\n",
    "sns.heatmap(df_corr, annot=False, vmax=1, square=True, cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c638ea8",
   "metadata": {},
   "source": [
    "# 3 特征筛选/降维"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c893b",
   "metadata": {},
   "source": [
    "## 3.1 分箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c46b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分箱\n",
    "bins = scorecardpy.woebin(df, y='credit_apply_flag', count_distr_limit=0.06, bin_num_limit=8)\n",
    "scorecardpy.woebin_plot(bins)#作图\n",
    "\n",
    "### iv\n",
    "\n",
    "# 获取分箱iv\n",
    "iv = pd.DataFrame() \n",
    "iv['features'] = [bins[i][['variable','total_iv']].drop_duplicates().loc[0]['variable'] for i in bins]\n",
    "iv['iv'] = [bins[i][['variable','total_iv']].drop_duplicates().loc[0]['total_iv'] for i in bins]\n",
    "ivs=iv.sort_values(['iv'],ascending=False)\n",
    "ivs.head()\n",
    "\n",
    "# 删掉iv值低/高的\n",
    "#IV值特征对预测函数的贡献\n",
    "#<0.03特征几乎不含有效信息，对模型没有贡献，这种特征可以被删除\n",
    "#0.03~0.09有效信息很少，对模型的贡献度低\n",
    "#0.1~0.29有效信息量一般，对模型的贡献度中等\n",
    "#0.3~0.49有效信息非常多，对模型的贡献度较高\n",
    "#=0.5有效信息非常多，对模型的贡献超高并且可疑\n",
    "droplist=list(iv[(iv.iv<0.02)|(iv.iv>0.6)]['features'])\n",
    "df=df.drop(droplist,axis=1)\n",
    "df.shape\n",
    "\n",
    "### vif \n",
    "\n",
    "#方差膨胀因子，检验多重共线性\n",
    "#两个自变量对应的方差膨胀因子均低于10，说明构 建模型的数据并不存在多重共线性。\n",
    "#如果发现变量之间存在多重共线性 的话，可以考虑删除变量或者重新选择模型\n",
    "X_vif = df.iloc[:,1:]\n",
    "vif = pd.DataFrame() \n",
    "vif[\"features\"] = X_vif.columns\n",
    "vif[\"vif\"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])] \n",
    "vif = pd.merge(vif,iv,how='left',on='features')\n",
    "vif.sort_values(['vif'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a524a3",
   "metadata": {},
   "source": [
    "## 3.2 XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "155c251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['credit_apply_flag']\n",
    "X = df.iloc[:,1:]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=0)\n",
    "X.shape,y.shape,X_train.shape,X_test.shape,y_train.shape,y_test.shape\n",
    "\n",
    "xgbm = xgb.XGBClassifier()\n",
    "xgbm.fit(X_train, y_train)\n",
    "\n",
    "# predicted proability\n",
    "train_pred = xgbm.predict_proba(X_train)[:,1]\n",
    "test_pred = xgbm.predict_proba(X_test)[:,1]\n",
    "# 预测结果\n",
    "y_train_pred = xgbm.predict(X_train) \n",
    "y_test_pred = xgbm.predict(X_test)\n",
    "\n",
    "# MSE 均方误差\n",
    "print('准确率:',xgbm.score(X_test, y_test)) # 全体\n",
    "print('ACC: %.4f' % metrics.accuracy_score(y_test,y_test_pred)) \n",
    "print('MSE:', metrics.mean_squared_error(y_test,y_test_pred))\n",
    "print('AUC: %.4f' % metrics.roc_auc_score(y_test,test_pred))\n",
    "print('Recall: %.4f' % metrics.recall_score(y_test,y_test_pred))  \n",
    "print('Precesion: %.4f' % metrics.precision_score(y_test,y_test_pred))  # y\n",
    "print('F1-score: %.4f' % metrics.f1_score(y_test,y_test_pred)) \n",
    "\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,test_pred)\n",
    "rocauc=metrics.auc(fpr,tpr)   #AUC，AUC>0.7，表示可接受的区辨能力\n",
    "print(\"AUC:\",rocauc)\n",
    "print(\"KS:\",max(tpr-fpr))  # KS值，KS>0.3，表示可接受的区辨能力\n",
    "\n",
    "confusion_matrix(y_test,y_test_pred)\n",
    "\n",
    "# 每个系数的影响力，系数越大表示特征在分类中起到的作用越大\n",
    "importance = pd.DataFrame({'features':X_train.columns,'importance':xgbm.feature_importances_}) \n",
    "importance.sort_values(['importance'],ascending=False)\n",
    "\n",
    "plot_importance(xgbm,max_num_features=20,importance_type='gain')  # 默认是importance_type='weight'\n",
    "plt.show()\n",
    "\n",
    "# gain是使用该特征切分的平均增益，weight是特征在树中出现的次数\n",
    "\n",
    "#fit model using each importance as a threshold\n",
    "thresholds = np.sort(xgbm.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(xgbm,threshold=thresh,prefit=True )\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    # train model\n",
    "    selection_model = xgb.XGBClassifier()\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    y_pred=(selection_model.predict_proba(select_X_test)[:,1]>0.5)*1\n",
    "    # y_pred = selection_model.predict(select_X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = metrics.accuracy_score(y_test,predictions)\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy * 100.0))\n",
    "\n",
    "# 确定最终入模特征\n",
    "p=[i for i in list(importance.sort_values(['importance'],ascending=False).head(15)['features'])]\n",
    "df=pd.concat([y,df[p]],axis=1)\n",
    "df.shape\n",
    "\n",
    "# 入模特征\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ddc51",
   "metadata": {},
   "source": [
    "## 3.3因子分析降维"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3a0e8",
   "metadata": {},
   "source": [
    "### 3.3.1数据标准化和适用性检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a58571f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用sklearn库进行数据标准化\n",
    "std = StandardScaler()\n",
    "df_fas1 = std.fit_transform(df_fa1)\n",
    "df_fas1 = pd.DataFrame(df_fas1, columns=df_fa1.columns)\n",
    "df_fas1.head()\n",
    "\n",
    "# kmo值要大于0.7\n",
    "kmo = calculate_kmo(df_fas1)  \n",
    "# bartlett球形度检验p值要小于0.05\n",
    "bartlett = calculate_bartlett_sphericity(df_fas1)  \n",
    "\n",
    "print(\"\\n因子分析适用性检验:\")\n",
    "print('kmo:{}    bartlett:{}'.format(kmo[1], bartlett[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d70cb",
   "metadata": {},
   "source": [
    "### 3.3.2 计算累计贡献率并确定因子个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a345f7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy.linalg as nlg #导入nlg函数，linalg=linear+algebra\n",
    "C=df_fa1.corr() #相关系数矩阵\n",
    "df_fa_cov1 = np.cov(df_fas1.T)\n",
    "eig_value1,eig_vector1=nlg.eig(df_fa_cov1) #计算特征值和特征向量\n",
    "eig1=pd.DataFrame() #利用变量名和特征值建立一个数据框\n",
    "eig1['names']=df_fa1.columns#列名\n",
    "eig1['eig_value1']=eig_value1#特征值\n",
    "eig1.head()\n",
    "\n",
    "#计算各特征值的方差贡献率\n",
    "w1 = list()\n",
    "for i in range(len(eig_value1)):\n",
    "    w1.append(eig1['eig_value1'][i] / eig1['eig_value1'].sum())\n",
    "#print(w)\n",
    "w1= pd.DataFrame(w1,columns =['贡献率'])\n",
    "w1.head()\n",
    "\n",
    "#计算特征值的累计贡献率\n",
    "q1 = list()\n",
    "for j in range(len(eig_value1)):\n",
    "    q1.append(eig1['eig_value1'][:j].sum() / eig1['eig_value1'].sum())\n",
    "#print(q)\n",
    "q1= pd.DataFrame(q1,columns =['累计贡献率'])\n",
    "q1.head()\n",
    "z1=pd.concat([w1,q1],axis=1)\n",
    "z1.to_csv('过往白_累计贡献率.csv',index=1,header=1,encoding='utf-8-sig')\n",
    "z1.head(6)\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "for k in range(1,20): #确定公共因子个数\n",
    "    if eig1['eig_value1'][:k].sum()/eig1['eig_value1'].sum()>=0.8: #如果解释度达到80%, 结束循环\n",
    "        print(k)\n",
    "        print(eig1['eig_value1'][:k].sum()/eig1['eig_value1'].sum())\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796cfd5b",
   "metadata": {},
   "source": [
    "### 3.3.3 计算旋转后的因子载荷矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0d4f5fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "A1=[]\n",
    "for i in range(5):\n",
    "    col=list(sqrt(eig_value1[i])*eig_vector1[:,i])\n",
    "    A1.append(col)\n",
    "A1=pd.DataFrame(A1).T #构造因子载荷矩阵A\n",
    "A1\n",
    "\n",
    "col=[]\n",
    "for i in range(1,6):\n",
    "    col.append('factor%d'%(i))\n",
    "A1.columns=[col] #因子载荷矩阵A的公共因子\n",
    "A1.head()\n",
    "\n",
    "h1=np.zeros(10) #变量共同度，反映变量对共同因子的依赖程度，越接近1，说明公共因子解释程度越高，因子分析效果越好\n",
    "D1=np.mat(np.eye(10))#特殊因子方差，因子的方差贡献度 ，反映公共因子对变量的贡献，衡量公共因子的相对重要性\n",
    "A1=np.mat(A1) #将因子载荷阵A矩阵化\n",
    "A1\n",
    "\n",
    "for i in range(10):\n",
    "    a=A1[i,:]*A1[i,:].T #A的元的行平方和\n",
    "    h1[i]=a[0,0]  #计算变量X共同度,描述全部公共因子F对变量X_i的总方差所做的贡献，及变量X_i方差中能够被全体因子解释的部分\n",
    "    D1[i,i]=1-a[0,0] #因为自变量矩阵已经标准化后的方差为1，即Var(X_i)=第i个共同度h_i + 第i个特殊因子方差\n",
    "\n",
    "from numpy import eye, asarray, dot, sum, diag #导入eye,asarray,dot,sum,diag 函数\n",
    "from numpy.linalg import svd #导入奇异值分解函数\n",
    "\n",
    "def varimax(Phi, gamma = 1.0, q =10, tol = 1e-6): #定义方差最大旋转函数\n",
    "    p,k = Phi.shape #给出矩阵Phi的总行数，总列数\n",
    "    R = eye(k) #给定一个k*k的单位矩阵\n",
    "    d=0\n",
    "    for i in range(q):\n",
    "        d_old = d\n",
    "        Lambda = dot(Phi, R)#矩阵乘法\n",
    "        u,s,vh = svd(dot(Phi.T,asarray(Lambda)**3 - (gamma/p) * dot(Lambda, diag(diag(dot(Lambda.T,Lambda)))))) #奇异值分解svd\n",
    "        R = dot(u,vh)#构造正交矩阵R\n",
    "        d = sum(s)#奇异值求和\n",
    "    if d_old!=0 and d/d_old:\n",
    "        return dot(Phi, R)#返回旋转矩阵Phi*R\n",
    "\n",
    "rotation_mat1=varimax(A1)#调用方差最大旋转函数\n",
    "rotation_mat1=pd.DataFrame(rotation_mat1)#数据框化\n",
    "rotation_mat1.columns=[col] \n",
    "rotation_mat1.insert(0,'变量名称',df_fas1.columns)\n",
    "rotation_mat1.to_csv('过往白_fas因子矩阵.csv',index=0,header=1,encoding=\"utf_8_sig\")\n",
    "rotation_mat1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce29e93",
   "metadata": {},
   "source": [
    "### 3.3.4计算因子得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf4ae50",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rotation_mat1=rotation_mat1.iloc[:,1:]\n",
    "data1=np.mat(df_fas1) #矩阵化处理\n",
    "factor_score=(data1).dot(rotation_mat1) #计算因子得分\n",
    "factor_score=pd.DataFrame(factor_score)#数据框化\n",
    "factor_score.columns=[col] #对因子变量进行命名\n",
    "factor_score\n",
    "#factor_score.to_excel(outputfile)#打印输出因子得分矩阵\n",
    "factor_score.to_csv('过往白_fas因子得分.csv',index=0,header=1,encoding=\"utf_8_sig\")\n",
    "factor_score.head()\n",
    "\n",
    "#检验因子相关性\n",
    "dff_corr=factor_score.corr()\n",
    "plt.figure(figsize=(30,8),dpi=60,facecolor='w')\n",
    "sns.heatmap(dff_corr, annot=False, vmax=1, square=True, cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3205b4",
   "metadata": {},
   "source": [
    "## 3.4 RandmForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f582479",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x, y = df.iloc[:, 1:].values, df.iloc[:, 0].values #0表示从第一列开始，即索引下标为0的列\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "feat_labels = df.columns[1:]\n",
    "forest = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=1)\n",
    "forest.fit(x_train, y_train)\n",
    "forest.score(x_test, y_test)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1] #[::-1]表示将各指标按权重大小进行排序输出\n",
    "\n",
    "indices[:33]\n",
    "for f in range(33):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))\n",
    "    \n",
    "\n",
    "# 每个系数的影响力，系数越大表示特征在分类中起到的作用越大\n",
    "importance = pd.DataFrame({'features':x_train.columns,'importance':forest.feature_importances_}) \n",
    "importance.sort_values(['importance'],ascending=False)\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(forest,'forest_test.m')  # 存储为文件\n",
    "\n",
    "# 调用模型\n",
    "df_test = df.iloc[:,1:].sample(n=3000,random_state=0).fillna(0)\n",
    "df_test.head()\n",
    "\n",
    "forest1 = joblib.load('forest_test.m')\n",
    "\n",
    "Y_pred = forest1.predict(df_test) \n",
    "Y_pred_pro = forest1.predict_proba(df_test)[:,1]\n",
    "print(Y_pred)\n",
    "print(Y_pred_pro)\n",
    "\n",
    "#画图\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "features = df.iloc[:, 1:].columns\n",
    "feature_importances = forest.feature_importances_\n",
    "features_df = pd.DataFrame({'Features':features,'Importance':feature_importances})\n",
    "features_df.sort_values('Importance',inplace=True,ascending=False)\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (20, 8)})\n",
    "sns.barplot(features_df['Features'][:12], features_df['Importance'][:12],palette=\"Blues_d\")\n",
    "plt.title(\"Importance of Features\",fontsize = 18)\n",
    "plt.ylabel('import level')\n",
    "plt.rcParams['font.sans-serif'] = [\"SimHei\"]\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 数据可视化：柱状图\n",
    "sns.despine(bottom=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33713ed8",
   "metadata": {},
   "source": [
    "## 3.5 GAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d93dcb0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x, y = df_21.iloc[:, 1:].values, df_21.iloc[:, 0].values #0表示从第一列开始，即索引下标为0的列\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "gam = LogisticGAM().fit(x_train, y_train)\n",
    "gam.accuracy(x_test,y_test)\n",
    "\n",
    "# Partial dependency plots\n",
    "total_features_fwd, score_dict_fwd = forward_stepwise_selection(df_21,'credit_apply_flag')\n",
    "features_selected = total_features_fwd[18]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (30, 5)\n",
    "fig, axs = plt.subplots(1,18)\n",
    "titles = features_selected\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    XX = gam.generate_X_grid(term=i)\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')\n",
    "    ax.set_title(titles[i])\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "#单图\n",
    "for i in range(len(df.columns)-1):\n",
    "    df_1 = pd.concat([df.iloc[:,0],df.iloc[:,i+1]],axis=1)\n",
    "    x, y = df_1.iloc[:, 1].values, df_1.iloc[:, 0].values #0表示从第一列开始，即索引下标为0的列\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "    gam = LogisticGAM().fit(x, y)\n",
    "    total_features_fwd, score_dict_fwd = forward_stepwise_selection(df_1,'credit_apply_flag')\n",
    "    features_selected = total_features_fwd[1]\n",
    "\n",
    "# Partial dependency plots\n",
    "    plt.rcParams['figure.figsize'] = (5, 5)\n",
    "    fig, axs = plt.subplots(1,1)\n",
    "    titles = features_selected\n",
    "\n",
    "#for i, ax in enumerate(axs):\n",
    "    XX = gam.generate_X_grid(term=0)\n",
    "    axs.plot(XX[:, 0], gam.partial_dependence(term=0, X=XX))\n",
    "    axs.plot(XX[:, 0], gam.partial_dependence(term=0, X=XX, width=.95)[1], c='r', ls='--')\n",
    "    axs.set_title(titles[0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac420e0",
   "metadata": {},
   "source": [
    "## 3.6 逐步向前线性回归算法变量筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d143749",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def forward_stepwise_selection(data,target):\n",
    "    \n",
    "    total_features = [[]]\n",
    "    score_dict = {}\n",
    "    remaining_features = [col for col in data.columns if not col == target]\n",
    "    \n",
    "    for i in range(1,len(data.columns)):\n",
    "        best_score = 0;best_feature = None\n",
    "        for feature in remaining_features:\n",
    "\n",
    "            X = total_features[i-1] + [feature]\n",
    "            model = LinearRegression().fit(data[X],data[target])\n",
    "            score = r2_score(data[target],model.predict(data[X]))\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_feature = feature\n",
    "        \n",
    "        total_features.append(total_features[i-1] + [best_feature])\n",
    "        remaining_features.remove(best_feature)\n",
    "        score_dict[i] = best_score\n",
    "    \n",
    "    return total_features,score_dict\n",
    "\n",
    "total_features_fwd, score_dict_fwd = forward_stepwise_selection(df,'credit_apply_flag')\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(df.drop('credit_apply_flag',axis = 1),df['credit_apply_flag'],test_size = 0.2)\n",
    "\n",
    "validation_scores_dict = {}\n",
    "for features in total_features_fwd[1:]:\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train[features],y_train)\n",
    "    preds = lr.predict(X_test[features])\n",
    "    validation_scores_dict[len(features)] = mean_squared_error(y_test,preds)\n",
    "    \n",
    "print(total_features_fwd)\n",
    "print(validation_scores_dict)\n",
    "\n",
    "# 选择特征,根据R2及MSE选取\n",
    "# By Validation error\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(list(validation_scores_dict.keys()),list(validation_scores_dict.values()))\n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel('Validation error')\n",
    "plt.title('Forward Selection_Validation error')\n",
    "\n",
    "# By r2 score\n",
    "temp = pd.DataFrame({'Number of Features':np.arange(1,len(total_features_fwd)),\n",
    "                     'R_2_score':list(score_dict_fwd.values())})\n",
    "plt.figure(figsize = (12,6))\n",
    "g = sns.FacetGrid(data = temp,size=5)\n",
    "g.map(plt.scatter, 'Number of Features' , 'R_2_score')\n",
    "g.map(plt.plot, 'Number of Features', 'R_2_score')\n",
    "plt.xticks = list(np.arange(1,len(total_features_fwd)))\n",
    "plt.title('Forward Selection_r2 score')\n",
    "\n",
    "features_selected = total_features_fwd[21]\n",
    "features_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0efb0dc",
   "metadata": {},
   "source": [
    "## 3.7逐步向前逻辑回归算法变量筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "370cef76",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def forward_select(data,response):\n",
    "    remaining=set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected=[]\n",
    "    current_score,best_new_score=float('inf'),float('inf')\n",
    "    while remaining:\n",
    "        aic_with_candidates=[]\n",
    "        for candidate in remaining:\n",
    "            formula='{}~{}'.format(response,'+'.join(selected+[candidate]))\n",
    "            aic=smf.glm(formula=formula,data=data,family=sm.families.Binomial(sm.families.links.logit)).fit().aic\n",
    "            aic_with_candidates.append((aic,candidate))\n",
    "        aic_with_candidates.sort(reverse=True)\n",
    "        best_new_score,best_candidate=aic_with_candidates.pop()\n",
    "        if current_score>best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score=best_new_score\n",
    "            print('aic is {},continuing!'.format(current_score))\n",
    "        else:\n",
    "            print('forward selection over!')\n",
    "            break\n",
    "    # 输出影响较大的自变量列表\n",
    "    formula='{}~{}'.format(response,'+'.join(selected))\n",
    "    print('final formula is {}'.format(formula))\n",
    "    return formula\n",
    "    # model=smf.glm(\n",
    "        # formula=formula,data=data,\n",
    "        # family=sm.families.Binomial(sm.families.links.logit)\n",
    "    # ).fit()\n",
    "    # return(model)\n",
    "    \n",
    "\n",
    "formula_fwd = forward_select(df,'credit_apply_flag')\n",
    "formula_fwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7819c6",
   "metadata": {},
   "source": [
    "# 4.建模"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ac86b",
   "metadata": {},
   "source": [
    "## 4.1 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "678a63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['credit_apply_flag']\n",
    "X = df.iloc[:,1:]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=0)\n",
    "X.shape,y.shape,X_train.shape,X_test.shape,y_train.shape,y_test.shape\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=0.9, solver='saga', n_jobs=-1, max_iter=3000)  # 增加迭代次数\n",
    "lr.fit(X_train, y_train)\n",
    "print(X_train.columns)\n",
    "print('系数',lr.coef_)\n",
    "print('截距',lr.intercept_)\n",
    "\n",
    "y_prob = lr.predict_proba(X_test)[:,1]\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"准确率:\",lr.score(X_test, y_test))\n",
    "print('MSE:',metrics.mean_squared_error(y_test,y_pred))\n",
    "#predict返回的是一个预测的值，predict_proba返回的是对于预测为各个类别的概率\n",
    "\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,y_prob)\n",
    "rocauc=metrics.auc(fpr,tpr)   # AUC，AUC>0.7，表示可接受的区辨能力\n",
    "print(\"AUC:\",rocauc)\n",
    "print(\"KS:\",max(tpr-fpr))  # KS值，KS>0.3，表示可接受的区辨能力\n",
    "\n",
    "lr2 = sm.Logit(y_train,X_train)\n",
    "print(lr2.fit().summary())\n",
    "#输出显著性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2fc4cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm)\n",
    "# print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "(tn, fp, fn, tp) \n",
    "\n",
    "sns.set_style('white') # 设置全局的图的背景为白色\n",
    "def show_cm(y_test, y_test_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "    plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.xticks([0,1])\n",
    "    plt.yticks([0,1])\n",
    "    plt.xlabel(\"Predict\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.text(x=0-0.1, y=0, s=\"TN:\"+str(tn), color='black') # 设置文本，位置由x,y确定，x,y为相对位置。0-1\n",
    "    plt.text(x=1-0.1, y=0, s=\"FP:\"+str(fp), color='black')\n",
    "    plt.text(x=0-0.1, y=1, s=\"FN:\"+str(fn), color='black')\n",
    "    plt.text(x=1-0.1, y=1, s=\"TP:\"+str(tp), color='black')\n",
    "    # 样本1的查准和召回：\n",
    "    查准率 = tp/(tp + fp)\n",
    "    召回率 = tp/(tp + tn)\n",
    "    print(\"查准率:\",查准率)\n",
    "    print(\"召回率:\",召回率)\n",
    "    plt.show()\n",
    "\n",
    "show_cm(y_test, y_test_pred)\n",
    "\n",
    "# performance ks & roc ------\n",
    "train_perf = scorecardpy.perf_eva(y_train, train_pred, title = \"train\")\n",
    "test_perf = scorecardpy.perf_eva(y_test, test_pred, title = \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e05f0",
   "metadata": {},
   "source": [
    "## 4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c06df1b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率 0.9047619047619049\n",
      "AUC 0.6044067678452473\n",
      "KS 0.20095868340468162\n",
      "MSE 0.09523809523809523\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,1:].reset_index(drop=True).values\n",
    "y = df['credit_apply_flag'].reset_index(drop=True).values\n",
    "xgbm = xgb.XGBClassifier(max_depth=5,learning_rate=0.1,n_estimators=1000,objective='binary:logistic')\n",
    "kf = StratifiedShuffleSplit(n_splits=10, train_size=0.9, test_size=0.1, random_state=0)\n",
    "accuracy_score = [] \n",
    "roc_auc_score = []\n",
    "mean_squared_error = []\n",
    "ks = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    xgbm.fit(X_train, y_train)\n",
    "    y_prob=xgbm.predict_proba(X_test)[:,1]\n",
    "    y_pred=xgbm.predict(X_test)\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test,y_pred))\n",
    "    roc_auc_score.append(metrics.roc_auc_score(y_test,y_prob))\n",
    "    mean_squared_error.append(metrics.mean_squared_error(y_test,y_pred))\n",
    "    fpr,tpr,threshold=metrics.roc_curve(y_test,y_prob)\n",
    "    rocauc=metrics.auc(fpr,tpr)\n",
    "    ks.append(max(tpr-fpr))\n",
    "    \n",
    "print('准确率', np.mean(accuracy_score))\n",
    "print('AUC', np.mean(roc_auc_score))\n",
    "print('KS', np.mean(ks))\n",
    "print('MSE', np.mean(mean_squared_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9df7f8e",
   "metadata": {},
   "source": [
    "## 4.3保存/调用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "8d76d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存\n",
    "joblib.dump(xgbm,'xgbm_visit_1.m')\n",
    "#调用\n",
    "xgbm111 = joblib.load('xgbm_visit_1.m')\n",
    "#预测\n",
    "xgbm111.predict(X_126).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ac942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17e69a9f",
   "metadata": {},
   "source": [
    "# 5.评价指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb33c1",
   "metadata": {},
   "source": [
    "## 5.1 ks曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b26a0a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# performance ks & roc ------\n",
    "#ks值含义:>0.3模型预测性较好；0,2~0.3模型可用；0~0.2模型预测能力较差；< 0模型错误\n",
    "\n",
    "test_perf = scorecardpy.perf_eva(y_test, y_prob, title = \"test\")\n",
    "\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,y_prob)\n",
    "print(\"KS:\",max(tpr-fpr))  # KS值，KS>0.3，表示可接受的区辨能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967b415",
   "metadata": {},
   "source": [
    "## 5.2 AUC和ROC曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,threshold=metrics.roc_curve(y_test,y_prob)\n",
    "rocauc=metrics.auc(fpr,tpr)   # AUC，AUC>0.7，表示可接受的区辨能力\n",
    "print(\"AUC:\",rocauc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c02102",
   "metadata": {},
   "source": [
    "# 6.调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e81dd77",
   "metadata": {},
   "source": [
    "## 6.1网格搜索法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da4253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch+交叉\n",
    "param_grid = [\n",
    "{'penalty': ['l1','l2'], 'C': [0.001,0.005,0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2]}\n",
    "]  \n",
    "lr = LogisticRegression(solver='saga', n_jobs=-1, max_iter=3000)  # 增加迭代次\n",
    "kf = StratifiedShuffleSplit(n_splits=10, train_size=0.9, test_size=0.1, random_state=0)#打乱划分\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=kf, scoring='roc_auc')  # neg_mean_squared_error\n",
    "grid_search.fit(X, Y)  # 作用于全量样本\n",
    "print (grid_search.best_params_)\n",
    "print (grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03bb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "#gridsearch+交叉\n",
    "param_grid = [\n",
    "{'n_estimators':[1000,4000,7000,10000],'max_depth':[3,4,5],'max_features':[4,7,10],'min_samples_split':[2,5,8,10],'min_samples_leaf':[1,3,5]}\n",
    "]  \n",
    "rf = RandomForestClassifier(random_state=0,n_jobs=-1,oob_score=True)\n",
    "kf = StratifiedShuffleSplit(n_splits=10, train_size=0.9, test_size=0.1, random_state=0)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=kf, scoring='roc_auc')  # neg_mean_squared_error\n",
    "grid_search.fit(X, Y)  # 作用于全量样本\n",
    "print (grid_search.best_params_)\n",
    "print (grid_search.best_estimator_)\n",
    "print('每轮迭代运行结果:')\n",
    "means = grid_search.cv_results_['mean_test_score']  # 输出5次训练的auc均值,取auc最大的参数组合\n",
    "params = grid_search.cv_results_['params'] \n",
    "for mean,param in zip(means,params):\n",
    "    print(\"%f  with:   %r\" % (mean,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c9102f",
   "metadata": {},
   "source": [
    "## 6.2手动调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa0e5f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#product(list1, list2) 依次取出list1中的每1个元素，与list2中的每1个元素，组成元组，\n",
    "#然后将所有的元组组成一个列表\n",
    "p=['l1','l2']\n",
    "c=[1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,2,3,4,5,6,7,8,9,10]\n",
    "for i,j in itertools.product(p,c):\n",
    "    lr = LogisticRegression(penalty=i, C=j, solver='saga', n_jobs=-1, max_iter=3000)  # 增加迭代次数\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_prob = lr.predict_proba(X_test)[:,1]\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print('penalty:',i)\n",
    "    print('C:',j)\n",
    "    fpr,tpr,threshold=metrics.roc_curve(y_test,y_prob)\n",
    "    rocauc=metrics.auc(fpr,tpr)   # AUC，AUC>0.7，表示可接受的区辨能力\n",
    "    print(\"AUC:\",rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9026193f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#XGB调参\n",
    "max_depth=[1,2,3,4]\n",
    "learning_rate=[0.001,0.005,0.01]\n",
    "n_estimators=[1000,4000,7000,10000]\n",
    "X = df.iloc[:,1:].reset_index(drop=True).values\n",
    "y = df['credit_apply_flag'].reset_index(drop=True).values\n",
    "kf = StratifiedShuffleSplit(n_splits=10, train_size=0.9, test_size=0.1, random_state=0)\n",
    "\n",
    "max_depth=3\n",
    "\n",
    "auc = []\n",
    "mse = []\n",
    "for i, j in itertools.product(learning_rate,n_estimators): \n",
    "    xgbm = xgb.XGBClassifier(learning_rate=i, n_estimators=j, max_depth=3, objective='binary:logistic')\n",
    "    roc_auc_score = []\n",
    "    mean_squared_error = []\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        xgbm.fit(X_train, y_train)\n",
    "        y_prob=xgbm.predict_proba(X_test)[:,1]\n",
    "        y_pred=xgbm.predict(X_test)\n",
    "        roc_auc_score.append(metrics.roc_auc_score(y_test,y_prob))\n",
    "        mean_squared_error.append(metrics.mean_squared_error(y_test,y_pred))\n",
    "    auc.append(np.mean(roc_auc_score))\n",
    "    mse.append(np.mean(mean_squared_error))\n",
    "    print('learning_rate', i) \n",
    "    print('n_estimators', j)\n",
    "    print('AUC', np.mean(roc_auc_score))\n",
    "    print('MSE', np.mean(mean_squared_error))\n",
    "print(auc)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed341a",
   "metadata": {},
   "source": [
    "# 7.验证集验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "481650a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示测预测概率对应的正负样本分布情况  \n",
    "test_result126 = test_df126[['credit_apply_flag','y_prob']]\n",
    "breaks_adj = {'y_prob': [0.02,0.05,0.09]}\n",
    "bins_score126 = scorecardpy.woebin(test_result126, y='credit_apply_flag',breaks_list=breaks_adj)\n",
    "scorecardpy.woebin_plot(bins_score126)\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "bins_score126['y_prob'].iloc[:,6].plot(label='badprob')\n",
    "bins_score126['y_prob'].iloc[:,3].plot(label='count_distr')\n",
    "plt.legend()\n",
    "\n",
    "dft126 = bins_score126['y_prob'].iloc[:,:7]\n",
    "dft126['bad']/dft126['bad'].sum()\n",
    "\n",
    "test1 = test_df126[['credit_apply_flag','y_prob']]\n",
    "bk1 = {'y_prob': list(np.linspace(0.01,0.5,50))}  # 每隔0.01画一个cut，np.linspace(),np.arange(),也可以写循环\n",
    "bins1 = scorecardpy.woebin(test1, y='credit_apply_flag',breaks_list=bk1)\n",
    "# scorecardpy.woebin_plot(bins1)\n",
    "\n",
    "dftest1 = bins1['y_prob'].iloc[:,:7]\n",
    "dftest1['cut']=list(np.linspace(0.01,0.5,49))\n",
    "dftest1=dftest1.sort_values(['cut'],ascending=False)\n",
    "dftest1['count_cumsum']=dftest1['count'].cumsum()\n",
    "dftest1['bad_cumsum']=dftest1['bad'].cumsum()\n",
    "dftest1['count_cumpct']=dftest1['count_cumsum']/dftest1['count'].sum()\n",
    "dftest1['bad_cumpct']=dftest1['bad_cumsum']/dftest1['bad'].sum()\n",
    "dftest1['gap']=dftest1['bad_cumpct']-dftest1['count_cumpct']\n",
    "dftest1.to_csv('过往白0.01间隔数据.csv')\n",
    "dftest1\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(dftest1['cut'],dftest1['count_cumpct'],label='msg_cumsumpct')\n",
    "plt.plot(dftest1['cut'],dftest1['bad_cumpct'],label='creditsubmit_cumsumpct')\n",
    "plt.xlabel('proability score')\n",
    "plt.ylabel('cumsumpct')\n",
    "plt.title('Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc147a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
